import random
import numpy as np

from giggleml.embedGen.embedPipeline import EmbedPipeline
from giggleml.embedGen import meanEmbedDict
from giggleml.embedGen.embedModel import HyenaDNA, CountACGT, TrivialModel
from giggleml.dataWrangling.intervalDataset import BedDataset


configfile: "config.yaml"
DATA = config['data']
HG = config['hg']

# include: "giggleLegacyExperiments.smk"
#
#
# rule synthesizeSequences:
#     params:
#         seqLenMin = int(1e3),
#         seqLenMax = int(25e3),
#         seqPerUniverse = int(2e5),
#         seed = 31415
#     output:
#         outFiles = [ f"{DATA}synthetic/intervals.bed" ],
#         fastaOut = f"{DATA}/synthetic/ref.fa"
#     run:
#         from src.synthesis import synthesize
#         synthesize(output.fastaOut, output.outFiles, *params)
#
#
# rule embedQualityTests:
#     params:
#         limit = 1000,  # some of the statistical tests are rather inefficient
#                        # and need an input limit to bound runtime
#         seed = 31415
#     input:
#         intervals = f"{DATA}/giggleBench/query.bed",
#         emebds = f"{DATA}/giggleBench/embeds/straight/query.npy",
#     output:
#         swtFig = "embedAnalysis/swt.png"
#     run:
#         random.seed(params.seed)
#         np.random.seed(params.seed)
#         runTests(input.intervals, input.emebds, params.limit, output.swtFig)


roadmapEpigBedPattern = DATA + "/roadmap_epigenomics/beds/{id}.bed"
roadmapEpigBedNames, = glob_wildcards(roadmapEpigBedPattern)

rule roadmapEpigenomicsEmbeds:
    # TODO: roadmap epi workflow should automatically start fiji job
    input:
        refGenome = HG + "/hg19.fa",
        bedFiles = expand(roadmapEpigBedPattern, id=roadmapEpigBedNames),
    output:
        embeds = expand(DATA + "/roadmap_epigenomics/embeds/{id}.npy",
                        id=roadmapEpigBedNames),
        # associated metadata should also be generated
        meta = expand(DATA + "/roadmap_epigenomics/embeds/{id}.npy.meta",
                      id=roadmapEpigBedNames),
        # the region set collection also produces a "master" mean embed dict
        master = DATA + "/roadmap_epigenomics/embeds/master.pickle"
    params:
        model = HyenaDNA("32k")
    run:
        batchSize = 64
        workerCount = 4
        subWorkerCount = 0  # the overhead is well not worth it

        inputData = [
          BedDataset(bed, associatedFastaPath=input.refGenome)
          for bed in input.bedFiles
        ]

        # big job
        EmbedPipeline(params.model, batchSize, workerCount, subWorkerCount) \
          .embed(intervals=inputData, out=output.embeds)
        # little job (produce $master)
        meanEmbedDict.build(output.embeds, output.master)
        print("Complete.")
